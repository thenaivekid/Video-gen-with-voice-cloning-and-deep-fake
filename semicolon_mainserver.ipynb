{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thenaivekid/Video-gen-with-voice-cloning-and-deep-fake/blob/main/semicolon_mainserver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ref https://youtu.be/otxB8PHjgak"
      ],
      "metadata": {
        "id": "mtVmmQb-kYoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# for wap2lip"
      ],
      "metadata": {
        "id": "Ks1RHWAIqStW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest-asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIEfP826ikIX",
        "outputId": "12048bef-5994-4cb2-b27a-38d67c7529c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "60berJgR4beO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/sample_data\n",
        "!mkdir /content/sample_data\n",
        "!mkdir /content/results\n",
        "!mkdir /content/temp\n",
        "\n",
        "!git clone https://github.com/zabique/Wav2Lip\n",
        "\n",
        "#download the pretrained model\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
        "a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "\n",
        "# !pip uninstall tensorflow tensorflow-gpu\n",
        "!cd Wav2Lip && pip install -r requirements.txt\n",
        "\n",
        "#download pretrained model for face detection\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
        "\n",
        "!pip install -q youtube-dl\n",
        "!pip install ffmpeg-python\n",
        "!pip install librosa==0.9.1\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def run_wav2lip_inference(audio_path, video_path, checkpoint_path=\"/content/Wav2Lip/checkpoints/wav2lip_gan.pth\"):\n",
        "    try:\n",
        "        command = [\n",
        "            \"python\", \"/content/Wav2Lip/inference.py\",\n",
        "            \"--checkpoint_path\", checkpoint_path,\n",
        "            \"--face\", video_path,\n",
        "            \"--audio\", audio_path,\n",
        "            \"--face_det_batch_size\", \"8\",\n",
        "            \"--resize_factor\", \"2\",\n",
        "            \"--outfile\", \"/content/results/output.mp4\"\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(command, capture_output=True, text=True)\n",
        "        print(\"Output:\", result.stdout)\n",
        "        print(\"Errors:\", result.stderr)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(\"Inference completed successfully!\")\n",
        "            return \"/content/results/output.mp4\"\n",
        "        else:\n",
        "            print(f\"Inference failed with return code {result.returncode}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "# run_wav2lip_inference(\"/content/t_audio.wav\", \"/content/muted_vid.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRsTHojAqRXa",
        "outputId": "7007db30-5db2-4807-e7ac-85052de509f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/results’: File exists\n",
            "mkdir: cannot create directory ‘/content/temp’: File exists\n",
            "fatal: destination path 'Wav2Lip' already exists and is not an empty directory.\n",
            "--2025-01-04 20:14:52--  https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA\n",
            "Resolving iiitaphyd-my.sharepoint.com (iiitaphyd-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to iiitaphyd-my.sharepoint.com (iiitaphyd-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435801865 (416M) [application/octet-stream]\n",
            "Saving to: ‘/content/Wav2Lip/checkpoints/wav2lip_gan.pth’\n",
            "\n",
            "/content/Wav2Lip/ch 100%[===================>] 415.61M   126MB/s    in 3.3s    \n",
            "\n",
            "2025-01-04 20:14:56 (126 MB/s) - ‘/content/Wav2Lip/checkpoints/wav2lip_gan.pth’ saved [435801865/435801865]\n",
            "\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.22.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.10.0.84)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.10.0.84)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.60.0)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 6)) (11.0.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 8)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 1)) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa->-r requirements.txt (line 1)) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->-r requirements.txt (line 1)) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 1)) (2024.12.14)\n",
            "--2025-01-04 20:15:03--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "/content/Wav2Lip/fa 100%[===================>]  85.68M  19.5MB/s    in 5.4s    \n",
            "\n",
            "2025-01-04 20:15:09 (15.9 MB/s) - ‘/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: librosa==0.9.1 in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.22.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (0.4.3)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa==0.9.1) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmEfa_2Y39cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "fastapi\n",
        "uvicorn\n",
        "pydantic\n",
        "yt-dlp\n",
        "moviepy\n",
        "numpy  # Required by MoviePy~\n",
        "pyngrok\n",
        "TTS\n",
        "cloudinary\n",
        "gdown\n",
        "langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbNGpkBluSM9",
        "outputId": "c62e40bd-82c6-4a56-e15a-75c63d0a6a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"NGROK_AUTHTOKEN\"] = \"2rAp3MN7tFzUaNn74AtnOx5Blek_49dmR43bRNVaFuYzPU9xt\""
      ],
      "metadata": {
        "id": "_mao2X7sxZvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC7LafveuYKc",
        "outputId": "9583278e-4234-43d6-a8d8-33c68c8d7dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.115.6)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.34.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.10.3)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2024.12.23)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.22.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (7.2.2)\n",
            "Requirement already satisfied: TTS in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.22.0)\n",
            "Requirement already satisfied: cloudinary in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.41.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.2.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.2.14)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->-r requirements.txt (line 1)) (0.41.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 5)) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 5)) (0.5.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 5)) (0.1.10)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok->-r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (3.0.11)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (1.11.4)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (2.5.1+cu121)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.12.1)\n",
            "Collecting librosa>=0.10.0 (from TTS->-r requirements.txt (line 8))\n",
            "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (7.4.0)\n",
            "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.3.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (3.11.10)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.3.4)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.5.7)\n",
            "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: trainer>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.0.36)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.0.17)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.53.0)\n",
            "Requirement already satisfied: hangul-romanize in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.1.0)\n",
            "Requirement already satisfied: gruut==2.2.3 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (2.2.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (3.9.1)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.1.2)\n",
            "Requirement already satisfied: bangla in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.0.2)\n",
            "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.0.2)\n",
            "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.8.0)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (4.47.1)\n",
            "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.1.1)\n",
            "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (1.3.8)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.5.14)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (3.7.5)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS->-r requirements.txt (line 8)) (0.60.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (2.16.0)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (1.1.8)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (2.0.1)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (2.8.8)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (0.9.11)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cloudinary->-r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.10/dist-packages (from cloudinary->-r requirements.txt (line 9)) (2.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from cloudinary->-r requirements.txt (line 9)) (2024.12.14)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 10)) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 10)) (3.16.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-openai->-r requirements.txt (line 11)) (0.3.29)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai->-r requirements.txt (line 11)) (1.59.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai->-r requirements.txt (line 11)) (0.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS->-r requirements.txt (line 8)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS->-r requirements.txt (line 8)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS->-r requirements.txt (line 8)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS->-r requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS->-r requirements.txt (line 8)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS->-r requirements.txt (line 8)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS->-r requirements.txt (line 8)) (1.18.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS->-r requirements.txt (line 8)) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS->-r requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS->-r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS->-r requirements.txt (line 8)) (1.9.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy->-r requirements.txt (line 5)) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy->-r requirements.txt (line 5)) (75.1.0)\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS->-r requirements.txt (line 8)) (10.5.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS->-r requirements.txt (line 8)) (4.4.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai->-r requirements.txt (line 11)) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai->-r requirements.txt (line 11)) (0.2.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai->-r requirements.txt (line 11)) (9.0.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS->-r requirements.txt (line 8)) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Using cached librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Using cached librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Using cached librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Using cached librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS->-r requirements.txt (line 8)) (1.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS->-r requirements.txt (line 8)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS->-r requirements.txt (line 8)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS->-r requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS->-r requirements.txt (line 8)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS->-r requirements.txt (line 8)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS->-r requirements.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->TTS->-r requirements.txt (line 8)) (0.6.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS->-r requirements.txt (line 8)) (0.43.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 11)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 11)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 11)) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS->-r requirements.txt (line 8)) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS->-r requirements.txt (line 8)) (1.17.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (0.15.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (0.6.9)\n",
            "Requirement already satisfied: sudachidict-core>=20211220 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (20241021)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai->-r requirements.txt (line 11)) (2024.11.6)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS->-r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1->TTS->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS->-r requirements.txt (line 8)) (2.17.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS->-r requirements.txt (line 8)) (0.27.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS->-r requirements.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS->-r requirements.txt (line 8)) (0.4.5)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.1->TTS->-r requirements.txt (line 8)) (0.5.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 10)) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 10)) (1.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 11)) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS->-r requirements.txt (line 8)) (2.22)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS->-r requirements.txt (line 8)) (5.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 11)) (1.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS->-r requirements.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai->-r requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai->-r requirements.txt (line 11)) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai->-r requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS->-r requirements.txt (line 8)) (4.3.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (7.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS->-r requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS->-r requirements.txt (line 8)) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS->-r requirements.txt (line 8)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS->-r requirements.txt (line 8)) (4.25.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS->-r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS->-r requirements.txt (line 8)) (0.1.2)\n",
            "Using cached librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "Installing collected packages: librosa\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.9.1\n",
            "    Uninstalling librosa-0.9.1:\n",
            "      Successfully uninstalled librosa-0.9.1\n",
            "Successfully installed librosa-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# saving to cloudinary"
      ],
      "metadata": {
        "id": "SFL_i4CgwOlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cloudinary\n",
        "import cloudinary.uploader\n",
        "\n",
        "cloudinary.config(\n",
        "    cloud_name=\"dbhckg5el\",\n",
        "    api_key=\"592613464587995\",\n",
        "    api_secret=\"uk1Ackb_FnPqLbX12ojf65Izct8\",\n",
        "    secure=True\n",
        ")\n",
        "\n",
        "def save_vid_to_cloudi(file_path):\n",
        "  cloudinary_response = cloudinary.uploader.upload(\n",
        "            file_path,\n",
        "            resource_type=\"video\"  # \"video\" supports audio files in Cloudinary\n",
        "        )\n",
        "  return cloudinary_response['secure_url']\n",
        "\n",
        "\n",
        "def upload_image_cloudi(img_path):\n",
        "  cloudinary_response = cloudinary.uploader.upload(\n",
        "            img_path,\n",
        "            resource_type=\"image\"  # \"video\" supports audio files in Cloudinary\n",
        "        )\n",
        "  return cloudinary_response['secure_url']"
      ],
      "metadata": {
        "id": "IdI5TUxtu0K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "def download_video(video_url, output_path=\"/content/download.mp4\"):\n",
        "    response = requests.get(video_url, stream=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(output_path, \"wb\") as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                file.write(chunk)\n",
        "        print(f\"Video downloaded successfully and saved to {output_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to download video. Status code: {response.status_code}\")\n",
        "    return output_path\n",
        "download_video(video_url=\"https://utfs.io/f/atDsyOESFTxlddd1bzke1mJ6pIFbfKrOEMkgH7vz3hPxianZ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2AK_U9h0Azzi",
        "outputId": "bc4e81c6-a0c2-4a03-f058-395493998639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully and saved to /content/download.mp4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/download.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# voice cloning"
      ],
      "metadata": {
        "id": "UuAz0dvqwMnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from TTS.api import TTS\n",
        "# from pyngrok import ngrok\n",
        "# import os\n",
        "# import requests\n",
        "# import tempfile\n",
        "# import cloudinary\n",
        "# import cloudinary.uploader\n",
        "# import gdown\n",
        "\n",
        "# tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
        "\n",
        "# def generate_tts(text, output_file_path, ref_audio_path, language='en'):\n",
        "#     tts.tts_to_file(\n",
        "#             text=text,\n",
        "#             file_path=output_file_path,\n",
        "#             speaker_wav=ref_audio_path,\n",
        "#             language=language\n",
        "#         )\n",
        "\n",
        "import requests\n",
        "\n",
        "def generate_tts(text, output_file_path, ref_audio_path, language='en'):\n",
        "\n",
        "\n",
        "\n",
        "  ref_audio_path = save_vid_to_cloudi(ref_audio_path)\n",
        "# Define the API endpoint\n",
        "  url = 'https://0a13-35-197-39-35.ngrok-free.app/tts'\n",
        "\n",
        "  # Define the headers\n",
        "  headers = {\n",
        "      'accept': 'application/json',\n",
        "      'Content-Type': 'application/json',\n",
        "  }\n",
        "\n",
        "  # Define the data payload\n",
        "  data = {\n",
        "      \"text\": text,\n",
        "      \"file_name\": \"x.mp4\",\n",
        "      \"source_audio_url\": ref_audio_path\n",
        "  }\n",
        "\n",
        "  # Make the POST request\n",
        "  response = requests.post(url, headers=headers, json=data)\n",
        "  print(response.json())\n",
        "  result=response.json()\n",
        "  url=result.get(\"cloudinary_url\")\n",
        "\n",
        "\n",
        "  output_path = download_video(url,output_path=output_file_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hDXyt46YuBW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GX4i4TvLxUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# call chate"
      ],
      "metadata": {
        "id": "X8sHCcN0wRWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Union\n",
        "import os\n",
        "\n",
        "# Define the structured output schema\n",
        "class ScriptPart(BaseModel):\n",
        "    text: str\n",
        "    vid: Union[str, None]  # Description of video clip or None\n",
        "    image: Union[str, None]  # Description of image or None\n",
        "    overlay_text: Union[str, None]  # Text overlay on screen if necessary\n",
        "\n",
        "class EducationalContent(BaseModel):\n",
        "    title: str\n",
        "    thumbnail: str  # Description for thumbnail generation\n",
        "    script: List[ScriptPart]  # List of script parts\n",
        "\n",
        "# Set OpenAI API key\n",
        "\n",
        "# Initialize OpenAI client\n",
        "llm = ChatOpenAI(\n",
        "    # model=\"gpt-4\",\n",
        "    model = \"gpt-4o\",\n",
        "    temperature=0,\n",
        "    max_tokens=3000,  # Adjust as needed\n",
        "    request_timeout=30,  # Optional timeout\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Define the parser\n",
        "parser = PydanticOutputParser(pydantic_object=EducationalContent)\n",
        "\n",
        "# Create the prompt template\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a YouTube video director, scriptwriter, and producer.Please make only 2 scenes. Given the user's style {style} and prompt {topic}, write a detailed script for the video. It should include:\"\n",
        "            \"\\n- A catchy title\"\n",
        "            \"\\n- Thumbnail description (detailed enough for an image generator)\"\n",
        "            \"\\n- A script with parts containing:\"\n",
        "            \"\\n    - Text spoken in the video\"\n",
        "            \"\\n    - Description of corresponding video clips or images\"\n",
        "            \"\\n    - Overlay text if necessary\"\n",
        "            \"\\n{format_instructions}\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def get_chate_response(topic, style=\"informative and engaging\",parser= parser, llm=llm, prompt_template=prompt_template):\n",
        "    formatted_prompt = prompt_template.format_prompt(\n",
        "        style=style,\n",
        "        topic=topic,\n",
        "        format_instructions=parser.get_format_instructions()\n",
        "    )\n",
        "\n",
        "    response = llm(formatted_prompt.to_messages())\n",
        "\n",
        "    structured_output = parser.parse(response.content)\n",
        "    print(\"chate out \", structured_output, type(structured_output))\n",
        "\n",
        "    return structured_output"
      ],
      "metadata": {
        "id": "dtWB5cL9wUza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Editor"
      ],
      "metadata": {
        "id": "nPKsfpdCxO8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import *\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "\n",
        "\n",
        "def create_text_overlay(text, size, font_path=\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", font_size=50, color=\"white\"):\n",
        "    img = Image.new(\"RGBA\", size, (0, 0, 0, 0))  # Transparent background\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "    # Draw text centered in the image\n",
        "    draw.multiline_text(\n",
        "        (size[0] // 2, size[1] // 2),  # Center of the image\n",
        "        text,\n",
        "        fill=color,\n",
        "        font=font,\n",
        "        anchor=\"mm\",  # Middle alignment for horizontal and vertical\n",
        "        align=\"center\",  # Center alignment for multiline\n",
        "    )\n",
        "    return img\n",
        "\n",
        "def edit_a_scene(text, vid_path, image_path, audio_path):\n",
        "    print(\"editing a scene\")\n",
        "    print(text)\n",
        "    print(vid_path)\n",
        "    print(image_path)\n",
        "    print(audio_path)\n",
        "    audio = AudioFileClip(audio_path)\n",
        "    duration = int(audio.duration)\n",
        "    video_clip = None\n",
        "    overlay_size = None\n",
        "    video_clip = VideoFileClip(vid_path).subclip(0, duration)\n",
        "    overlay_size = video_clip.get_frame(0).shape[:2]\n",
        "    # if vid_path:\n",
        "    #     # todo\n",
        "    #     vid_path=\"/content/results/output.mp4\"\n",
        "    #     video_clip = VideoFileClip(vid_path).subclip(0, duration)\n",
        "    #     overlay_size = video_clip.get_frame(0).shape[:2]\n",
        "    # else:\n",
        "    #     # todo\n",
        "    #     image_path = \"/content/temp.png\"\n",
        "    #     video_clip = ImageClip(image_path, duration=duration)\n",
        "    #     overlay_size = video_clip.size\n",
        "    video_clip = video_clip.set_audio(audio)\n",
        "    # if text:\n",
        "    #     text_overlay_image = create_text_overlay(text, overlay_size)\n",
        "    #     text_overlay_path = \"/content/text_overlay.png\"\n",
        "    #     text_overlay_image.save(text_overlay_path)\n",
        "    #     text_overlay_clip = ImageClip(text_overlay_path, duration=duration).set_position(\"center\")\n",
        "\n",
        "\n",
        "    #     video_clip = CompositeVideoClip([video_clip, text_overlay_clip])\n",
        "    return video_clip\n",
        "\n",
        "def concat_scenes(scene_clips):\n",
        "    '''scene_clips is python list of VideoClips'''\n",
        "    final_clip = concatenate_videoclips(scene_clips)\n",
        "    print(\"concat done \", type(final_clip))\n",
        "    output_path = \"/content/final_video.mp4\"\n",
        "    final_clip.write_videofile(output_path,codec='libx264',audio_codec='aac')\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "D8eckhoh2U8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# server: where they all come together"
      ],
      "metadata": {
        "id": "etyqRKQRKsm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fza2Stz1DBup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_voHvLNDuL-7",
        "outputId": "518c4947-384f-4a90-cd08-9c44d73404f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public_URL:  https://65cd-34-125-33-192.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1787]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "t:   3%|▎         | 8/290 [06:32<3:50:19, 49.01s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully and saved to /content/download.mp4\n",
            "MoviePy - Writing audio in /content/t_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "chunk:   0%|          | 0/480 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "chunk:  42%|████▏     | 202/480 [00:00<00:00, 2017.64it/s, now=None]\u001b[A\n",
            "chunk:  84%|████████▍ | 404/480 [00:00<00:00, 1873.31it/s, now=None]\u001b[A\n",
            "t:   3%|▎         | 8/290 [06:32<3:50:29, 49.04s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Building video /content/muted_vid.mp4.\n",
            "Moviepy - Writing video /content/muted_vid.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "t:   0%|          | 0/150 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "t:   8%|▊         | 12/150 [00:00<00:01, 117.46it/s, now=None]\u001b[A\n",
            "t:  16%|█▌        | 24/150 [00:00<00:01, 107.60it/s, now=None]\u001b[A\n",
            "t:  24%|██▍       | 36/150 [00:00<00:01, 110.56it/s, now=None]\u001b[A\n",
            "t:  32%|███▏      | 48/150 [00:00<00:01, 66.34it/s, now=None] \u001b[A\n",
            "t:  38%|███▊      | 57/150 [00:00<00:01, 49.55it/s, now=None]\u001b[A\n",
            "t:  43%|████▎     | 64/150 [00:01<00:02, 42.06it/s, now=None]\u001b[A\n",
            "t:  47%|████▋     | 70/150 [00:01<00:02, 38.65it/s, now=None]\u001b[A\n",
            "t:  50%|█████     | 75/150 [00:01<00:02, 33.36it/s, now=None]\u001b[A\n",
            "t:  53%|█████▎    | 79/150 [00:01<00:02, 31.87it/s, now=None]\u001b[A\n",
            "t:  55%|█████▌    | 83/150 [00:01<00:02, 32.06it/s, now=None]\u001b[A\n",
            "t:  58%|█████▊    | 87/150 [00:01<00:02, 31.18it/s, now=None]\u001b[A\n",
            "t:  61%|██████    | 91/150 [00:02<00:01, 30.59it/s, now=None]\u001b[A\n",
            "t:  63%|██████▎   | 95/150 [00:02<00:01, 29.93it/s, now=None]\u001b[A\n",
            "t:  66%|██████▌   | 99/150 [00:02<00:01, 28.81it/s, now=None]\u001b[A\n",
            "t:  69%|██████▊   | 103/150 [00:02<00:01, 28.87it/s, now=None]\u001b[A\n",
            "t:  71%|███████▏  | 107/150 [00:02<00:01, 28.27it/s, now=None]\u001b[A\n",
            "t:  74%|███████▍  | 111/150 [00:02<00:01, 27.94it/s, now=None]\u001b[A\n",
            "t:  77%|███████▋  | 115/150 [00:03<00:01, 27.46it/s, now=None]\u001b[A\n",
            "t:  79%|███████▉  | 119/150 [00:03<00:01, 27.94it/s, now=None]\u001b[A\n",
            "t:  81%|████████▏ | 122/150 [00:03<00:00, 28.07it/s, now=None]\u001b[A\n",
            "t:  83%|████████▎ | 125/150 [00:03<00:00, 27.73it/s, now=None]\u001b[A\n",
            "t:  85%|████████▌ | 128/150 [00:03<00:00, 26.27it/s, now=None]\u001b[A\n",
            "t:  87%|████████▋ | 131/150 [00:03<00:00, 26.40it/s, now=None]\u001b[A\n",
            "t:  89%|████████▉ | 134/150 [00:03<00:00, 27.16it/s, now=None]\u001b[A\n",
            "t:  92%|█████████▏| 138/150 [00:03<00:00, 28.20it/s, now=None]\u001b[A\n",
            "t:  95%|█████████▍| 142/150 [00:03<00:00, 29.92it/s, now=None]\u001b[A\n",
            "t:  97%|█████████▋| 145/150 [00:04<00:00, 28.08it/s, now=None]\u001b[A\n",
            "t:  99%|█████████▊| 148/150 [00:04<00:00, 27.96it/s, now=None]\u001b[A\n",
            "t:   3%|▎         | 8/290 [06:37<3:53:33, 49.69s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/muted_vid.mp4\n",
            "chate out  title='The AI Revolution: Transforming Our World' thumbnail=\"A futuristic cityscape with AI robots interacting with humans, digital data streams flowing through the air, and a large, bold text overlay saying 'AI Revolution'.\" script=[ScriptPart(text='Welcome to the AI Revolution, where artificial intelligence is not just a concept of the future, but a reality shaping our present.', vid='intro_sequence.mp4', image=None, overlay_text='The AI Revolution'), ScriptPart(text='From healthcare to transportation, AI is transforming industries at an unprecedented pace. But what does this mean for us?', vid='industries_transformation.mp4', image=None, overlay_text='AI in Healthcare and Transportation')] <class '__main__.EducationalContent'>\n",
            "script generated\n",
            "Scenes [ScriptPart(text='Welcome to the AI Revolution, where artificial intelligence is not just a concept of the future, but a reality shaping our present.', vid='intro_sequence.mp4', image=None, overlay_text='The AI Revolution'), ScriptPart(text='From healthcare to transportation, AI is transforming industries at an unprecedented pace. But what does this mean for us?', vid='industries_transformation.mp4', image=None, overlay_text='AI in Healthcare and Transportation')]\n",
            "{'cloudinary_url': 'https://res.cloudinary.com/dbhckg5el/video/upload/v1736025537/avlkmi6odlkqxej6se2y.wav'}\n",
            "Video downloaded successfully and saved to /content/scene_audio.wav\n",
            "TTS done for one Scene\n",
            "Output: Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 150\n",
            "(80, 568)\n",
            "Length of mel chunks: 209\n",
            "Load checkpoint from: /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "\n",
            "Errors: RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n",
            "/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/content/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_weights = torch.load(path_to_detector)\n",
            "\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  5%|▌         | 1/19 [00:03<00:58,  3.27s/it]\u001b[A\n",
            "\n",
            " 11%|█         | 2/19 [00:03<00:24,  1.46s/it]\u001b[A\n",
            "\n",
            " 16%|█▌        | 3/19 [00:03<00:14,  1.14it/s]\u001b[A\n",
            "\n",
            " 21%|██        | 4/19 [00:03<00:09,  1.66it/s]\u001b[A\n",
            "\n",
            " 26%|██▋       | 5/19 [00:04<00:06,  2.22it/s]\u001b[A\n",
            "\n",
            " 32%|███▏      | 6/19 [00:04<00:04,  2.76it/s]\u001b[A\n",
            "\n",
            " 37%|███▋      | 7/19 [00:04<00:03,  3.25it/s]\u001b[A\n",
            "\n",
            " 42%|████▏     | 8/19 [00:04<00:02,  3.75it/s]\u001b[A\n",
            "\n",
            " 47%|████▋     | 9/19 [00:04<00:02,  4.15it/s]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 10/19 [00:04<00:02,  4.49it/s]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 11/19 [00:05<00:01,  4.80it/s]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 12/19 [00:05<00:01,  4.99it/s]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 13/19 [00:05<00:01,  5.14it/s]\u001b[A\n",
            "\n",
            " 74%|███████▎  | 14/19 [00:05<00:00,  5.25it/s]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 15/19 [00:05<00:00,  5.33it/s]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 16/19 [00:06<00:00,  5.38it/s]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 17/19 [00:06<00:00,  5.40it/s]\u001b[A\n",
            "\n",
            " 95%|█████████▍| 18/19 [00:06<00:00,  5.44it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 19/19 [00:08<00:00,  1.16it/s]\u001b[A\n",
            "100%|██████████| 19/19 [00:08<00:00,  2.15it/s]\n",
            "/content/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "\n",
            " 50%|█████     | 1/2 [00:19<00:19, 19.37s/it]\n",
            "100%|██████████| 2/2 [00:25<00:00, 11.61s/it]\n",
            "100%|██████████| 2/2 [00:25<00:00, 12.78s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Guessed Channel Layout for Input Stream #0.0 : mono\n",
            "Input #0, wav, from '/content/scene_audio.wav':\n",
            "  Duration: 00:00:07.09, bitrate: 384 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:06.97, start: 0.000000, bitrate: 811 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 240x424 [SAR 1:1 DAR 30:53], 802 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x55c2fc0509c0] -qscale is ignored, -crf is recommended.\n",
            "[libx264 @ 0x55c2fc0509c0] using SAR=1/1\n",
            "[libx264 @ 0x55c2fc0509c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "[libx264 @ 0x55c2fc0509c0] profile High, level 2.1, 4:2:0, 8-bit\n",
            "[libx264 @ 0x55c2fc0509c0] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/results/output.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 240x424 [SAR 1:1 DAR 30:53], q=2-31, 30 fps, 15360 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=    1 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
            "frame=   93 fps=0.0 q=29.0 size=       0kB time=00:00:01.49 bitrate=   0.3kbits/s speed= 2.9x    \n",
            "frame=  157 fps=154 q=29.0 size=       0kB time=00:00:03.56 bitrate=   0.1kbits/s speed=3.51x    \n",
            "frame=  209 fps=119 q=-1.0 Lsize=     231kB time=00:00:07.08 bitrate= 267.2kbits/s speed=4.05x    \n",
            "video:169kB audio:55kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.960480%\n",
            "[libx264 @ 0x55c2fc0509c0] frame I:1     Avg QP:21.88  size:  6787\n",
            "[libx264 @ 0x55c2fc0509c0] frame P:92    Avg QP:23.61  size:  1430\n",
            "[libx264 @ 0x55c2fc0509c0] frame B:116   Avg QP:26.74  size:   292\n",
            "[libx264 @ 0x55c2fc0509c0] consecutive B-frames: 23.9%  4.8%  4.3% 67.0%\n",
            "[libx264 @ 0x55c2fc0509c0] mb I  I16..4: 20.5% 71.6%  7.9%\n",
            "[libx264 @ 0x55c2fc0509c0] mb P  I16..4:  1.0%  3.7%  0.0%  P16..4: 33.8% 13.9%  8.1%  0.0%  0.0%    skip:39.6%\n",
            "[libx264 @ 0x55c2fc0509c0] mb B  I16..4:  0.2%  0.6%  0.0%  B16..8: 36.6%  2.1%  0.2%  direct: 2.5%  skip:57.7%  L0:48.6% L1:47.7% BI: 3.7%\n",
            "[libx264 @ 0x55c2fc0509c0] 8x8 transform intra:76.5% inter:71.9%\n",
            "[libx264 @ 0x55c2fc0509c0] coded y,uvDC,uvAC intra: 24.3% 26.5% 4.7% inter: 9.9% 8.4% 0.0%\n",
            "[libx264 @ 0x55c2fc0509c0] i16 v,h,dc,p: 48% 42%  7%  2%\n",
            "[libx264 @ 0x55c2fc0509c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 13% 12% 67%  1%  1%  2%  1%  1%  2%\n",
            "[libx264 @ 0x55c2fc0509c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 28% 23%  4%  6%  7%  9%  5%  6%\n",
            "[libx264 @ 0x55c2fc0509c0] i8c dc,h,v,p: 62% 24% 12%  2%\n",
            "[libx264 @ 0x55c2fc0509c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
            "[libx264 @ 0x55c2fc0509c0] ref P L0: 61.6% 15.4% 15.5%  7.5%\n",
            "[libx264 @ 0x55c2fc0509c0] ref B L0: 83.2% 12.7%  4.1%\n",
            "[libx264 @ 0x55c2fc0509c0] ref B L1: 92.9%  7.1%\n",
            "[libx264 @ 0x55c2fc0509c0] kb/s:197.80\n",
            "[aac @ 0x55c2fc051d40] Qavg: 5350.752\n",
            "\n",
            "Inference completed successfully!\n",
            "Wav2Lip done for one Scene\n",
            "editing a scene\n",
            "The AI Revolution\n",
            "/content/results/output.mp4\n",
            "None\n",
            "/content/scene_audio.wav\n",
            "Editing done for one Scene\n",
            "added a scene\n",
            "{'cloudinary_url': 'https://res.cloudinary.com/dbhckg5el/video/upload/v1736025579/qio6nxgtme0gscik0msd.wav'}\n",
            "Video downloaded successfully and saved to /content/scene_audio.wav\n",
            "TTS done for one Scene\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:   3%|▎         | 8/290 [07:58<4:40:50, 59.75s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 150\n",
            "(80, 731)\n",
            "Length of mel chunks: 270\n",
            "Load checkpoint from: /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "\n",
            "Errors: RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n",
            "/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]/content/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_weights = torch.load(path_to_detector)\n",
            "\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  5%|▌         | 1/19 [00:03<01:02,  3.45s/it]\u001b[A\n",
            "\n",
            " 11%|█         | 2/19 [00:03<00:26,  1.53s/it]\u001b[A\n",
            "\n",
            " 16%|█▌        | 3/19 [00:03<00:14,  1.09it/s]\u001b[A\n",
            "\n",
            " 21%|██        | 4/19 [00:04<00:09,  1.60it/s]\u001b[A\n",
            "\n",
            " 26%|██▋       | 5/19 [00:04<00:06,  2.16it/s]\u001b[A\n",
            "\n",
            " 32%|███▏      | 6/19 [00:04<00:04,  2.73it/s]\u001b[A\n",
            "\n",
            " 37%|███▋      | 7/19 [00:04<00:03,  3.27it/s]\u001b[A\n",
            "\n",
            " 42%|████▏     | 8/19 [00:04<00:02,  3.77it/s]\u001b[A\n",
            "\n",
            " 47%|████▋     | 9/19 [00:04<00:02,  4.21it/s]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 10/19 [00:05<00:01,  4.57it/s]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 11/19 [00:05<00:01,  4.86it/s]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 12/19 [00:05<00:01,  5.10it/s]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 13/19 [00:05<00:01,  5.27it/s]\u001b[A\n",
            "\n",
            " 74%|███████▎  | 14/19 [00:05<00:00,  5.38it/s]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 15/19 [00:05<00:00,  5.47it/s]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 16/19 [00:06<00:00,  5.53it/s]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 17/19 [00:06<00:00,  5.56it/s]\u001b[A\n",
            "\n",
            " 95%|█████████▍| 18/19 [00:06<00:00,  5.59it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 19/19 [00:08<00:00,  1.19it/s]\u001b[A\n",
            "100%|██████████| 19/19 [00:08<00:00,  2.15it/s]\n",
            "/content/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "\n",
            " 33%|███▎      | 1/3 [00:19<00:38, 19.36s/it]\n",
            " 67%|██████▋   | 2/3 [00:19<00:08,  8.26s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  5.45s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.32s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Guessed Channel Layout for Input Stream #0.0 : mono\n",
            "Input #0, wav, from '/content/scene_audio.wav':\n",
            "  Duration: 00:00:09.13, bitrate: 384 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:09.00, start: 0.000000, bitrate: 796 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 240x424 [SAR 1:1 DAR 30:53], 788 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x55ab524c6ec0] -qscale is ignored, -crf is recommended.\n",
            "[libx264 @ 0x55ab524c6ec0] using SAR=1/1\n",
            "[libx264 @ 0x55ab524c6ec0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "[libx264 @ 0x55ab524c6ec0] profile High, level 2.1, 4:2:0, 8-bit\n",
            "[libx264 @ 0x55ab524c6ec0] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/results/output.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 240x424 [SAR 1:1 DAR 30:53], q=2-31, 30 fps, 15360 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=    1 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
            "frame=  131 fps=0.0 q=29.0 size=       0kB time=00:00:02.70 bitrate=   0.1kbits/s speed= 5.3x    \n",
            "frame=  226 fps=223 q=29.0 size=       0kB time=00:00:05.93 bitrate=   0.1kbits/s speed=5.85x    \n",
            "frame=  270 fps=192 q=-1.0 Lsize=     302kB time=00:00:09.13 bitrate= 271.1kbits/s speed= 6.5x    \n",
            "video:222kB audio:72kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.778590%\n",
            "[libx264 @ 0x55ab524c6ec0] frame I:2     Avg QP:21.04  size:  7538\n",
            "[libx264 @ 0x55ab524c6ec0] frame P:120   Avg QP:23.54  size:  1416\n",
            "[libx264 @ 0x55ab524c6ec0] frame B:148   Avg QP:26.78  size:   279\n",
            "[libx264 @ 0x55ab524c6ec0] consecutive B-frames: 23.0%  9.6%  6.7% 60.7%\n",
            "[libx264 @ 0x55ab524c6ec0] mb I  I16..4: 16.5% 69.9% 13.6%\n",
            "[libx264 @ 0x55ab524c6ec0] mb P  I16..4:  0.8%  3.3%  0.0%  P16..4: 34.2% 13.8%  8.3%  0.0%  0.0%    skip:39.5%\n",
            "[libx264 @ 0x55ab524c6ec0] mb B  I16..4:  0.2%  0.5%  0.0%  B16..8: 36.8%  2.0%  0.2%  direct: 2.3%  skip:58.2%  L0:47.6% L1:49.0% BI: 3.5%\n",
            "[libx264 @ 0x55ab524c6ec0] 8x8 transform intra:76.6% inter:70.9%\n",
            "[libx264 @ 0x55ab524c6ec0] coded y,uvDC,uvAC intra: 27.3% 29.1% 6.7% inter: 9.9% 8.4% 0.0%\n",
            "[libx264 @ 0x55ab524c6ec0] i16 v,h,dc,p: 46% 46%  5%  3%\n",
            "[libx264 @ 0x55ab524c6ec0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 11% 63%  2%  2%  2%  1%  2%  3%\n",
            "[libx264 @ 0x55ab524c6ec0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 21% 18% 19%  6%  8%  8%  7%  7%  7%\n",
            "[libx264 @ 0x55ab524c6ec0] i8c dc,h,v,p: 61% 24% 13%  2%\n",
            "[libx264 @ 0x55ab524c6ec0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
            "[libx264 @ 0x55ab524c6ec0] ref P L0: 62.7% 15.2% 15.2%  6.9%\n",
            "[libx264 @ 0x55ab524c6ec0] ref B L0: 82.7% 13.3%  4.0%\n",
            "[libx264 @ 0x55ab524c6ec0] ref B L1: 94.7%  5.3%\n",
            "[libx264 @ 0x55ab524c6ec0] kb/s:201.10\n",
            "[aac @ 0x55ab524cb900] Qavg: 8157.471\n",
            "\n",
            "Inference completed successfully!\n",
            "Wav2Lip done for one Scene\n",
            "editing a scene\n",
            "AI in Healthcare and Transportation\n",
            "/content/results/output.mp4\n",
            "None\n",
            "/content/scene_audio.wav\n",
            "Editing done for one Scene\n",
            "added a scene\n",
            "concat done  <class 'moviepy.video.VideoClip.VideoClip'>\n",
            "Moviepy - Building video /content/final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "chunk:   0%|          | 0/356 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "chunk:  29%|██▊       | 102/356 [00:00<00:00, 977.78it/s, now=None]\u001b[A\n",
            "chunk:  57%|█████▋    | 204/356 [00:00<00:00, 996.45it/s, now=None]\u001b[A\n",
            "chunk:  85%|████████▌ | 304/356 [00:00<00:00, 975.83it/s, now=None]\u001b[A\n",
            "t:   3%|▎         | 8/290 [07:58<4:41:04, 59.80s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "t:   0%|          | 0/480 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "t:  12%|█▏        | 59/480 [00:00<00:00, 557.24it/s, now=None]\u001b[A\n",
            "t:  24%|██▍       | 115/480 [00:00<00:00, 367.54it/s, now=None]\u001b[A\n",
            "t:  33%|███▎      | 158/480 [00:00<00:00, 388.72it/s, now=None]\u001b[A\n",
            "t:  42%|████▏     | 200/480 [00:00<00:00, 378.60it/s, now=None]\u001b[A\n",
            "t:  50%|█████     | 240/480 [00:00<00:00, 360.10it/s, now=None]\u001b[A\n",
            "t:  58%|█████▊    | 277/480 [00:00<00:00, 329.05it/s, now=None]\u001b[A\n",
            "t:  65%|██████▍   | 311/480 [00:00<00:00, 265.03it/s, now=None]\u001b[A\n",
            "t:  71%|███████   | 340/480 [00:01<00:00, 235.08it/s, now=None]\u001b[A\n",
            "t:  76%|███████▋  | 366/480 [00:01<00:00, 213.23it/s, now=None]\u001b[A\n",
            "t:  81%|████████  | 389/480 [00:01<00:00, 207.58it/s, now=None]\u001b[A\n",
            "t:  86%|████████▌ | 411/480 [00:01<00:00, 189.15it/s, now=None]\u001b[A\n",
            "t:  90%|████████▉ | 431/480 [00:01<00:00, 183.24it/s, now=None]\u001b[A\n",
            "t:  94%|█████████▍| 450/480 [00:01<00:00, 177.87it/s, now=None]\u001b[A\n",
            "t:  98%|█████████▊| 468/480 [00:01<00:00, 172.19it/s, now=None]\u001b[A\n",
            "t:   3%|▎         | 8/290 [08:00<4:42:22, 60.08s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/final_video.mp4\n",
            "concatenated all scenes\n",
            "saved to cloudinary\n",
            "INFO:     43.245.85.164:0 - \"POST /generate/ HTTP/1.1\" 200 OK\n",
            "INFO:     43.245.85.164:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     43.245.85.164:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     43.245.85.164:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     43.245.85.164:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:   3%|▎         | 8/290 [13:56<8:11:32, 104.58s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully and saved to /content/download.mp4\n",
            "MoviePy - Writing audio in /content/t_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "chunk:   0%|          | 0/480 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "chunk:  52%|█████▏    | 248/480 [00:00<00:00, 2476.00it/s, now=None]\u001b[A\n",
            "t:   3%|▎         | 8/290 [13:56<8:11:40, 104.61s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Building video /content/muted_vid.mp4.\n",
            "Moviepy - Writing video /content/muted_vid.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "t:   0%|          | 0/150 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "t:  13%|█▎        | 19/150 [00:00<00:00, 185.52it/s, now=None]\u001b[A\n",
            "t:  25%|██▌       | 38/150 [00:00<00:00, 174.99it/s, now=None]\u001b[A\n",
            "t:  37%|███▋      | 56/150 [00:00<00:01, 92.26it/s, now=None] \u001b[A\n",
            "t:  46%|████▌     | 69/150 [00:00<00:01, 68.86it/s, now=None]\u001b[A\n",
            "t:  53%|█████▎    | 79/150 [00:01<00:01, 57.27it/s, now=None]\u001b[A\n",
            "t:  58%|█████▊    | 87/150 [00:01<00:01, 54.23it/s, now=None]\u001b[A\n",
            "t:  63%|██████▎   | 94/150 [00:01<00:01, 54.13it/s, now=None]\u001b[A\n",
            "t:  67%|██████▋   | 101/150 [00:01<00:00, 50.12it/s, now=None]\u001b[A\n",
            "t:  71%|███████▏  | 107/150 [00:01<00:00, 49.12it/s, now=None]\u001b[A\n",
            "t:  75%|███████▌  | 113/150 [00:01<00:00, 46.94it/s, now=None]\u001b[A\n",
            "t:  79%|███████▊  | 118/150 [00:01<00:00, 45.96it/s, now=None]\u001b[A\n",
            "t:  82%|████████▏ | 123/150 [00:02<00:00, 42.76it/s, now=None]\u001b[A\n",
            "t:  85%|████████▌ | 128/150 [00:02<00:00, 44.15it/s, now=None]\u001b[A\n",
            "t:  89%|████████▊ | 133/150 [00:02<00:00, 45.27it/s, now=None]\u001b[A\n",
            "t:  92%|█████████▏| 138/150 [00:02<00:00, 46.21it/s, now=None]\u001b[A\n",
            "t:  95%|█████████▌| 143/150 [00:02<00:00, 42.68it/s, now=None]\u001b[A\n",
            "t:  99%|█████████▊| 148/150 [00:02<00:00, 43.44it/s, now=None]\u001b[A\n",
            "t:   3%|▎         | 8/290 [14:00<8:13:45, 105.05s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/muted_vid.mp4\n",
            "chate out  title='The Magic Behind Web Programming: From Code to Creation' thumbnail='A vibrant image of a computer screen displaying colorful lines of code, with a silhouette of a person in front of it, symbolizing the journey of web programming. The background is a blend of digital elements like binary code and web icons, creating a futuristic and engaging look.' script=[ScriptPart(text=\"Welcome to the fascinating world of web programming! Today, we're diving into the magic that turns lines of code into the websites we use every day.\", vid='intro_animation.mp4', image=None, overlay_text='The Magic Behind Web Programming'), ScriptPart(text=\"Web programming is the backbone of the internet. It involves writing code that instructs computers on how to display web pages. But it's not just about making things look pretty; it's about creating interactive and functional experiences.\", vid=None, image='web_programming_concept.jpg', overlay_text='Web Programming: More Than Just Code')] <class '__main__.EducationalContent'>\n",
            "script generated\n",
            "Scenes [ScriptPart(text=\"Welcome to the fascinating world of web programming! Today, we're diving into the magic that turns lines of code into the websites we use every day.\", vid='intro_animation.mp4', image=None, overlay_text='The Magic Behind Web Programming'), ScriptPart(text=\"Web programming is the backbone of the internet. It involves writing code that instructs computers on how to display web pages. But it's not just about making things look pretty; it's about creating interactive and functional experiences.\", vid=None, image='web_programming_concept.jpg', overlay_text='Web Programming: More Than Just Code')]\n",
            "{'cloudinary_url': 'https://res.cloudinary.com/dbhckg5el/video/upload/v1736025983/unhpqwzrbbrf2bssa6cx.wav'}\n",
            "Video downloaded successfully and saved to /content/scene_audio.wav\n",
            "TTS done for one Scene\n",
            "Output: Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 150\n",
            "(80, 806)\n",
            "Length of mel chunks: 298\n",
            "Load checkpoint from: /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "\n",
            "Errors: RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n",
            "/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]/content/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_weights = torch.load(path_to_detector)\n",
            "\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  5%|▌         | 1/19 [00:03<00:57,  3.22s/it]\u001b[A\n",
            "\n",
            " 11%|█         | 2/19 [00:03<00:24,  1.43s/it]\u001b[A\n",
            "\n",
            " 16%|█▌        | 3/19 [00:03<00:13,  1.16it/s]\u001b[A\n",
            "\n",
            " 21%|██        | 4/19 [00:03<00:08,  1.69it/s]\u001b[A\n",
            "\n",
            " 26%|██▋       | 5/19 [00:03<00:06,  2.27it/s]\u001b[A\n",
            "\n",
            " 32%|███▏      | 6/19 [00:04<00:04,  2.85it/s]\u001b[A\n",
            "\n",
            " 37%|███▋      | 7/19 [00:04<00:03,  3.40it/s]\u001b[A\n",
            "\n",
            " 42%|████▏     | 8/19 [00:04<00:02,  3.91it/s]\u001b[A\n",
            "\n",
            " 47%|████▋     | 9/19 [00:04<00:02,  4.34it/s]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 10/19 [00:04<00:01,  4.66it/s]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 11/19 [00:04<00:01,  4.94it/s]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 12/19 [00:05<00:01,  5.17it/s]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 13/19 [00:05<00:01,  5.31it/s]\u001b[A\n",
            "\n",
            " 74%|███████▎  | 14/19 [00:05<00:00,  5.43it/s]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 15/19 [00:05<00:00,  5.52it/s]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 16/19 [00:05<00:00,  5.56it/s]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 17/19 [00:06<00:00,  5.62it/s]\u001b[A\n",
            "\n",
            " 95%|█████████▍| 18/19 [00:06<00:00,  5.65it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 19/19 [00:08<00:00,  1.20it/s]\u001b[A\n",
            "100%|██████████| 19/19 [00:08<00:00,  2.21it/s]\n",
            "/content/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "\n",
            " 33%|███▎      | 1/3 [00:19<00:38, 19.04s/it]\n",
            " 67%|██████▋   | 2/3 [00:19<00:08,  8.10s/it]\n",
            "100%|██████████| 3/3 [00:23<00:00,  6.15s/it]\n",
            "100%|██████████| 3/3 [00:23<00:00,  7.77s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Guessed Channel Layout for Input Stream #0.0 : mono\n",
            "Input #0, wav, from '/content/scene_audio.wav':\n",
            "  Duration: 00:00:10.07, bitrate: 384 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:09.93, start: 0.000000, bitrate: 798 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 240x424 [SAR 1:1 DAR 30:53], 790 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x58b09259c1c0] -qscale is ignored, -crf is recommended.\n",
            "[libx264 @ 0x58b09259c1c0] using SAR=1/1\n",
            "[libx264 @ 0x58b09259c1c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "[libx264 @ 0x58b09259c1c0] profile High, level 2.1, 4:2:0, 8-bit\n",
            "[libx264 @ 0x58b09259c1c0] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/results/output.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 240x424 [SAR 1:1 DAR 30:53], q=2-31, 30 fps, 15360 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=    1 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
            "frame=  103 fps=0.0 q=29.0 size=       0kB time=00:00:01.76 bitrate=   0.2kbits/s speed=3.47x    \n",
            "frame=  172 fps=169 q=29.0 size=       0kB time=00:00:04.06 bitrate=   0.1kbits/s speed=   4x    \n",
            "frame=  234 fps=154 q=29.0 size=       0kB time=00:00:06.13 bitrate=   0.1kbits/s speed=4.03x    \n",
            "frame=  298 fps=130 q=-1.0 Lsize=     333kB time=00:00:10.06 bitrate= 270.8kbits/s speed=4.38x    \n",
            "video:242kB audio:82kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.756230%\n",
            "[libx264 @ 0x58b09259c1c0] frame I:2     Avg QP:20.97  size:  7670\n",
            "[libx264 @ 0x58b09259c1c0] frame P:125   Avg QP:23.45  size:  1462\n",
            "[libx264 @ 0x58b09259c1c0] frame B:171   Avg QP:26.46  size:   287\n",
            "[libx264 @ 0x58b09259c1c0] consecutive B-frames: 20.1%  9.4%  2.0% 68.5%\n",
            "[libx264 @ 0x58b09259c1c0] mb I  I16..4: 11.1% 76.3% 12.6%\n",
            "[libx264 @ 0x58b09259c1c0] mb P  I16..4:  0.9%  3.4%  0.0%  P16..4: 34.6% 14.3%  8.2%  0.0%  0.0%    skip:38.5%\n",
            "[libx264 @ 0x58b09259c1c0] mb B  I16..4:  0.2%  0.5%  0.0%  B16..8: 36.9%  2.0%  0.2%  direct: 2.6%  skip:57.5%  L0:47.2% L1:49.1% BI: 3.7%\n",
            "[libx264 @ 0x58b09259c1c0] 8x8 transform intra:76.8% inter:71.0%\n",
            "[libx264 @ 0x58b09259c1c0] coded y,uvDC,uvAC intra: 25.6% 27.8% 6.5% inter: 9.7% 8.5% 0.0%\n",
            "[libx264 @ 0x58b09259c1c0] i16 v,h,dc,p: 49% 42%  7%  3%\n",
            "[libx264 @ 0x58b09259c1c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 12% 62%  2%  2%  2%  1%  2%  2%\n",
            "[libx264 @ 0x58b09259c1c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19% 20% 18%  6%  7%  8%  6%  8%  8%\n",
            "[libx264 @ 0x58b09259c1c0] i8c dc,h,v,p: 63% 23% 12%  2%\n",
            "[libx264 @ 0x58b09259c1c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
            "[libx264 @ 0x58b09259c1c0] ref P L0: 61.3% 14.9% 16.3%  7.5%\n",
            "[libx264 @ 0x58b09259c1c0] ref B L0: 83.2% 12.7%  4.0%\n",
            "[libx264 @ 0x58b09259c1c0] ref B L1: 92.9%  7.1%\n",
            "[libx264 @ 0x58b09259c1c0] kb/s:199.04\n",
            "[aac @ 0x58b0925a0e40] Qavg: 7671.758\n",
            "\n",
            "Inference completed successfully!\n",
            "Wav2Lip done for one Scene\n",
            "editing a scene\n",
            "The Magic Behind Web Programming\n",
            "/content/results/output.mp4\n",
            "None\n",
            "/content/scene_audio.wav\n",
            "Editing done for one Scene\n",
            "added a scene\n",
            "{'cloudinary_url': 'https://res.cloudinary.com/dbhckg5el/video/upload/v1736026027/te5bhzdls4hin2veq30j.wav'}\n",
            "Video downloaded successfully and saved to /content/scene_audio.wav\n",
            "TTS done for one Scene\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:   3%|▎         | 8/290 [15:32<9:07:34, 116.51s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 150\n",
            "(80, 1243)\n",
            "Length of mel chunks: 462\n",
            "Load checkpoint from: /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "\n",
            "Errors: RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n",
            "/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]/content/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_weights = torch.load(path_to_detector)\n",
            "\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  5%|▌         | 1/19 [00:03<00:58,  3.25s/it]\u001b[A\n",
            "\n",
            " 11%|█         | 2/19 [00:03<00:24,  1.45s/it]\u001b[A\n",
            "\n",
            " 16%|█▌        | 3/19 [00:03<00:13,  1.15it/s]\u001b[A\n",
            "\n",
            " 21%|██        | 4/19 [00:03<00:09,  1.67it/s]\u001b[A\n",
            "\n",
            " 26%|██▋       | 5/19 [00:03<00:06,  2.24it/s]\u001b[A\n",
            "\n",
            " 32%|███▏      | 6/19 [00:04<00:04,  2.79it/s]\u001b[A\n",
            "\n",
            " 37%|███▋      | 7/19 [00:04<00:03,  3.34it/s]\u001b[A\n",
            "\n",
            " 42%|████▏     | 8/19 [00:04<00:02,  3.79it/s]\u001b[A\n",
            "\n",
            " 47%|████▋     | 9/19 [00:04<00:02,  4.21it/s]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 10/19 [00:04<00:01,  4.56it/s]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 11/19 [00:05<00:01,  4.83it/s]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 12/19 [00:05<00:01,  5.07it/s]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 13/19 [00:05<00:01,  5.22it/s]\u001b[A\n",
            "\n",
            " 74%|███████▎  | 14/19 [00:05<00:00,  5.34it/s]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 15/19 [00:05<00:00,  5.37it/s]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 16/19 [00:05<00:00,  5.43it/s]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 17/19 [00:06<00:00,  5.46it/s]\u001b[A\n",
            "\n",
            " 95%|█████████▍| 18/19 [00:06<00:00,  5.48it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 19/19 [00:08<00:00,  1.16it/s]\u001b[A\n",
            "100%|██████████| 19/19 [00:08<00:00,  2.17it/s]\n",
            "/content/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "\n",
            " 25%|██▌       | 1/4 [00:19<00:57, 19.27s/it]\n",
            " 50%|█████     | 2/4 [00:19<00:16,  8.23s/it]\n",
            " 75%|███████▌  | 3/4 [00:20<00:04,  4.68s/it]\n",
            "100%|██████████| 4/4 [00:26<00:00,  5.21s/it]\n",
            "100%|██████████| 4/4 [00:26<00:00,  6.56s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Guessed Channel Layout for Input Stream #0.0 : mono\n",
            "Input #0, wav, from '/content/scene_audio.wav':\n",
            "  Duration: 00:00:15.53, bitrate: 384 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:15.40, start: 0.000000, bitrate: 799 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 240x424 [SAR 1:1 DAR 30:53], 792 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x580372eb10c0] -qscale is ignored, -crf is recommended.\n",
            "[libx264 @ 0x580372eb10c0] using SAR=1/1\n",
            "[libx264 @ 0x580372eb10c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "[libx264 @ 0x580372eb10c0] profile High, level 2.1, 4:2:0, 8-bit\n",
            "[libx264 @ 0x580372eb10c0] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/results/output.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 240x424 [SAR 1:1 DAR 30:53], q=2-31, 30 fps, 15360 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=    1 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
            "frame=   91 fps=0.0 q=29.0 size=       0kB time=00:00:01.40 bitrate=   0.3kbits/s speed=2.71x    \n",
            "frame=  172 fps=169 q=29.0 size=       0kB time=00:00:04.06 bitrate=   0.1kbits/s speed=3.98x    \n",
            "frame=  265 fps=174 q=29.0 size=       0kB time=00:00:07.21 bitrate=   0.1kbits/s speed=4.74x    \n",
            "frame=  362 fps=179 q=29.0 size=     256kB time=00:00:10.45 bitrate= 200.7kbits/s speed=5.17x    \n",
            "frame=  458 fps=182 q=29.0 size=     256kB time=00:00:13.61 bitrate= 154.1kbits/s speed= 5.4x    \n",
            "frame=  462 fps=169 q=-1.0 Lsize=     511kB time=00:00:15.53 bitrate= 269.8kbits/s speed=5.67x    \n",
            "video:376kB audio:123kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.588275%\n",
            "[libx264 @ 0x580372eb10c0] frame I:2     Avg QP:21.00  size:  7601\n",
            "[libx264 @ 0x580372eb10c0] frame P:207   Avg QP:23.49  size:  1426\n",
            "[libx264 @ 0x580372eb10c0] frame B:253   Avg QP:26.61  size:   291\n",
            "[libx264 @ 0x580372eb10c0] consecutive B-frames: 24.9%  4.8%  4.5% 65.8%\n",
            "[libx264 @ 0x580372eb10c0] mb I  I16..4: 11.5% 74.7% 13.8%\n",
            "[libx264 @ 0x580372eb10c0] mb P  I16..4:  1.1%  3.4%  0.0%  P16..4: 34.0% 14.0%  8.1%  0.0%  0.0%    skip:39.3%\n",
            "[libx264 @ 0x580372eb10c0] mb B  I16..4:  0.2%  0.6%  0.0%  B16..8: 37.1%  2.1%  0.2%  direct: 2.6%  skip:57.2%  L0:46.9% L1:49.3% BI: 3.8%\n",
            "[libx264 @ 0x580372eb10c0] 8x8 transform intra:75.4% inter:71.1%\n",
            "[libx264 @ 0x580372eb10c0] coded y,uvDC,uvAC intra: 22.5% 25.7% 5.1% inter: 10.0% 8.6% 0.0%\n",
            "[libx264 @ 0x580372eb10c0] i16 v,h,dc,p: 53% 38%  5%  4%\n",
            "[libx264 @ 0x580372eb10c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 12% 67%  1%  1%  2%  1%  1%  2%\n",
            "[libx264 @ 0x580372eb10c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 23% 18%  6%  7%  7%  6%  6%  8%\n",
            "[libx264 @ 0x580372eb10c0] i8c dc,h,v,p: 64% 24% 11%  2%\n",
            "[libx264 @ 0x580372eb10c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
            "[libx264 @ 0x580372eb10c0] ref P L0: 62.0% 15.2% 15.4%  7.4%\n",
            "[libx264 @ 0x580372eb10c0] ref B L0: 83.7% 11.8%  4.4%\n",
            "[libx264 @ 0x580372eb10c0] ref B L1: 92.8%  7.2%\n",
            "[libx264 @ 0x580372eb10c0] kb/s:199.42\n",
            "[aac @ 0x580372eb2680] Qavg: 7543.198\n",
            "\n",
            "Inference completed successfully!\n",
            "Wav2Lip done for one Scene\n",
            "editing a scene\n",
            "Web Programming: More Than Just Code\n",
            "/content/results/output.mp4\n",
            "None\n",
            "/content/scene_audio.wav\n",
            "Editing done for one Scene\n",
            "added a scene\n",
            "concat done  <class 'moviepy.video.VideoClip.VideoClip'>\n",
            "Moviepy - Building video /content/final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "chunk:   0%|          | 0/563 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "chunk:  16%|█▌        | 91/563 [00:00<00:00, 908.32it/s, now=None]\u001b[A\n",
            "chunk:  34%|███▍      | 194/563 [00:00<00:00, 979.61it/s, now=None]\u001b[A\n",
            "chunk:  52%|█████▏    | 292/563 [00:00<00:00, 962.93it/s, now=None]\u001b[A\n",
            "chunk:  69%|██████▉   | 389/563 [00:00<00:00, 952.00it/s, now=None]\u001b[A\n",
            "chunk:  86%|████████▌ | 485/563 [00:00<00:00, 945.00it/s, now=None]\u001b[A\n",
            "t:   3%|▎         | 8/290 [15:32<9:07:56, 116.58s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "t:   0%|          | 0/750 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "t:   8%|▊         | 59/750 [00:00<00:01, 569.46it/s, now=None]\u001b[A\n",
            "t:  15%|█▌        | 116/750 [00:00<00:01, 323.50it/s, now=None]\u001b[A\n",
            "t:  22%|██▏       | 162/750 [00:00<00:01, 366.43it/s, now=None]\u001b[A\n",
            "t:  27%|██▋       | 204/750 [00:00<00:01, 378.29it/s, now=None]\u001b[A\n",
            "t:  33%|███▎      | 246/750 [00:00<00:01, 386.66it/s, now=None]\u001b[A\n",
            "t:  38%|███▊      | 288/750 [00:00<00:01, 393.57it/s, now=None]\u001b[A\n",
            "t:  44%|████▍     | 329/750 [00:00<00:01, 373.51it/s, now=None]\u001b[A\n",
            "t:  49%|████▉     | 368/750 [00:01<00:01, 319.41it/s, now=None]\u001b[A\n",
            "t:  54%|█████▎    | 402/750 [00:01<00:01, 245.47it/s, now=None]\u001b[A\n",
            "t:  57%|█████▋    | 430/750 [00:01<00:01, 226.26it/s, now=None]\u001b[A\n",
            "t:  61%|██████    | 455/750 [00:01<00:01, 211.31it/s, now=None]\u001b[A\n",
            "t:  64%|██████▎   | 478/750 [00:01<00:01, 204.37it/s, now=None]\u001b[A\n",
            "t:  67%|██████▋   | 500/750 [00:01<00:01, 199.78it/s, now=None]\u001b[A\n",
            "t:  69%|██████▉   | 521/750 [00:01<00:01, 190.70it/s, now=None]\u001b[A\n",
            "t:  72%|███████▏  | 541/750 [00:02<00:01, 180.50it/s, now=None]\u001b[A\n",
            "t:  75%|███████▍  | 560/750 [00:02<00:01, 179.13it/s, now=None]\u001b[A\n",
            "t:  77%|███████▋  | 579/750 [00:02<00:01, 164.20it/s, now=None]\u001b[A\n",
            "t:  80%|███████▉  | 597/750 [00:02<00:00, 167.08it/s, now=None]\u001b[A\n",
            "t:  82%|████████▏ | 615/750 [00:02<00:00, 170.32it/s, now=None]\u001b[A\n",
            "t:  84%|████████▍ | 633/750 [00:02<00:00, 170.51it/s, now=None]\u001b[A\n",
            "t:  87%|████████▋ | 651/750 [00:02<00:00, 172.26it/s, now=None]\u001b[A\n",
            "t:  89%|████████▉ | 669/750 [00:02<00:00, 168.15it/s, now=None]\u001b[A\n",
            "t:  91%|█████████▏| 686/750 [00:02<00:00, 166.89it/s, now=None]\u001b[A\n",
            "t:  94%|█████████▍| 704/750 [00:03<00:00, 169.52it/s, now=None]\u001b[A\n",
            "t:  96%|█████████▋| 722/750 [00:03<00:00, 172.02it/s, now=None]\u001b[A\n",
            "t:  99%|█████████▊| 740/750 [00:03<00:00, 164.84it/s, now=None]\u001b[A\n",
            "t:   3%|▎         | 8/290 [15:36<9:10:02, 117.03s/it, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/final_video.mp4\n",
            "concatenated all scenes\n",
            "saved to cloudinary\n",
            "INFO:     43.245.85.164:0 - \"POST /generate/ HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "# %%writefile test.py\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from moviepy.editor import VideoFileClip\n",
        "import yt_dlp\n",
        "import os\n",
        "from pathlib import Path\n",
        "from pyngrok import ngrok\n",
        "app = FastAPI()\n",
        "import requests\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "# Allow all CORS origins\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class VideoRequest(BaseModel):\n",
        "    sample_vid_url: str\n",
        "    video_script :str\n",
        "\n",
        "@app.post(\"/generate/\")\n",
        "def generate_video(video_request: VideoRequest):\n",
        "    url = video_request.sample_vid_url\n",
        "\n",
        "    video_output = download_video(video_url=url)\n",
        "    ref_audio_path = \"/content/t_audio.wav\"\n",
        "    muted_vid_output = \"/content/muted_vid.mp4\"\n",
        "    try:\n",
        "        clip = VideoFileClip(str(video_output))\n",
        "        clip.audio.write_audiofile(ref_audio_path)\n",
        "        video_clip = clip.without_audio()\n",
        "        video_clip = video_clip.subclip(0,5)\n",
        "        video_clip.write_videofile(muted_vid_output, codec=\"libx264\", audio_codec=\"aac\")\n",
        "        script = get_chate_response(video_request.video_script)\n",
        "        print(\"script generated\")\n",
        "\n",
        "        # todo create thumbnail image upload to cloudy using upload_image_cloudi(img_path)\n",
        "\n",
        "        scenes = script.script\n",
        "        print(\"Scenes\",scenes)\n",
        "\n",
        "        scene_clips = []\n",
        "        for scene in scenes:\n",
        "            temp_audio_path = \"/content/scene_audio.wav\"\n",
        "            generate_tts(scene.text, temp_audio_path, ref_audio_path)\n",
        "            print(\"TTS done for one Scene\")\n",
        "            temp_video_path = run_wav2lip_inference(audio_path=temp_audio_path, video_path=muted_vid_output)\n",
        "            print(\"Wav2Lip done for one Scene\")\n",
        "            # todo generate video and image as needed and pass the path\n",
        "            scene_clip = edit_a_scene(text=scene.overlay_text, vid_path=temp_video_path, image_path=None, audio_path=temp_audio_path)\n",
        "            print(\"Editing done for one Scene\")\n",
        "\n",
        "            scene_clips.append(scene_clip)\n",
        "            print(\"added a scene\")\n",
        "        output_path = concat_scenes(scene_clips)\n",
        "        print(\"concatenated all scenes\")\n",
        "        output_url=save_vid_to_cloudi(output_path)\n",
        "        print(\"saved to cloudinary\")\n",
        "        return {\n",
        "            \"message\": \"Video generated successfully\",\n",
        "            \"video_url\": output_url\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Error extracting audio: {e}\")\n",
        "\n",
        "    return {\n",
        "        \"message\": \"Video and audio processed successfully\",\n",
        "        \"video_path\": str(video_output),\n",
        "        \"audio_path\": str(audio_output)\n",
        "    }\n",
        "\n",
        "# Cleanup at app shutdown\n",
        "# @app.on_event(\"shutdown\")\n",
        "# def cleanup():\n",
        "#     for file in Path(\"downloads\").iterdir():\n",
        "#         file.unlink()\n",
        "#     Path(\"downloads\").rmdir()\n",
        "\n",
        "# @app.on_event(\"startup\")\n",
        "# def startup_event():\n",
        "#     public_url = ngrok.connect(8000)\n",
        "#     print(f\"Public URL: {public_url}\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  import uvicorn\n",
        "  ngrok_tunnel=ngrok.connect(8000)\n",
        "  print('Public_URL: ',ngrok_tunnel.public_url)\n",
        "  nest_asyncio.apply()\n",
        "  uvicorn.run(app)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-tYUm5fihNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCddpHk0iYeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NjVo1qjryKIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] from chate: get the catchy name, thumbnail image, script, imagaries."
      ],
      "metadata": {
        "id": "CK31lmDzGlMx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2B8Og1ZIPBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UXMybwsoIe91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.schema import HumanMessage\n",
        "# from typing import List, Tuple\n",
        "# from langchain.output_parsers import PydanticOutputParser\n",
        "# from langchain.prompts import ChatPromptTemplate\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# import os\n",
        "\n",
        "# # GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "# # OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# GOOGLE_API_KEY = \"\"\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "# # chate = ChatOpenAI(\n",
        "# #     model_name=\"gpt-4-turbo\",\n",
        "# #     openai_api_key=OPENAI_API_KEY\n",
        "# # )\n",
        "\n",
        "\n",
        "# llm = ChatGoogleGenerativeAI(\n",
        "#     model=\"gemini-1.5-pro\",\n",
        "#     temperature=0,\n",
        "#     max_tokens=None,\n",
        "#     timeout=None,\n",
        "#     max_retries=2,\n",
        "#     # other params...\n",
        "# )\n",
        "\n",
        "# prompt = ChatPromptTemplate.from_messages(\n",
        "#     [\n",
        "#         (\n",
        "#             \"system\",\n",
        "#             \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
        "#         ),\n",
        "#         (\"human\", \"{input}\"),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# chain = prompt | llm\n",
        "# chain.invoke(\n",
        "#     {\n",
        "#         \"input_language\": \"English\",\n",
        "#         \"output_language\": \"German\",\n",
        "#         \"input\": \"I love programming.\",\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "prHl1Bu_QUmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.schema import HumanMessage\n",
        "# from langchain.output_parsers import PydanticOutputParser\n",
        "# from langchain.prompts import ChatPromptTemplate\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# import os\n",
        "# from pydantic import BaseModel\n",
        "# from typing import List, Dict, Union\n",
        "\n",
        "# # Define the structured output schema\n",
        "# class ScriptPart(BaseModel):\n",
        "#     text: str\n",
        "#     vid: Union[str, None]  # Description of video clip or None\n",
        "#     image: Union[str, None]  # Description of image or None\n",
        "#     overlay_text: Union[str, None]  # Text overlay on screen if necessary\n",
        "\n",
        "# class EducationalContent(BaseModel):\n",
        "#     title: str\n",
        "#     thumbnail: str  # Description for thumbnail generation\n",
        "#     script: List[ScriptPart]  # List of script parts\n",
        "\n",
        "# # Initialize Google Generative AI client\n",
        "# GOOGLE_API_KEY = \"AIzaSyCuUGY9g-LdKcrUsXITmoZHAO8fFPC93t0\"\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# llm = ChatGoogleGenerativeAI(\n",
        "#     model=\"gemini-1.5-pro\",\n",
        "#     temperature=0,\n",
        "#     max_tokens=None,\n",
        "#     timeout=None,\n",
        "#     max_retries=2,\n",
        "# )\n",
        "\n",
        "# # Define the parser\n",
        "# parser = PydanticOutputParser(pydantic_object=EducationalContent)\n",
        "\n",
        "# # Create the prompt\n",
        "# prompt = ChatPromptTemplate.from_messages(\n",
        "#     [\n",
        "#         (\n",
        "#             \"system\",\n",
        "#             \"You are a YouTube video director, scriptwriter, and producer. Given the user's style {style} and prompt {prompt}, write a detailed script for the video. It should contain:\"\n",
        "#             \"\\n- A catchy title\"\n",
        "#             \"\\n- Thumbnail description (detailed enough for an image generator)\"\n",
        "#             \"\\n- A script broken into parts with:\"\n",
        "#             \"\\n    - Text spoken in the video\"\n",
        "#             \"\\n    - Description of corresponding video clips or images\"\n",
        "#             \"\\n    - Overlay text if necessary\"\n",
        "#             \"\\nReturn the output in the specified structured format.\",\n",
        "#         ),\n",
        "#         (\"human\", \"{input}\"),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# # Chain prompt and LLM\n",
        "# chain = prompt | llm | parser\n",
        "\n",
        "# # Invoke the chain with input\n",
        "# response = chain.invoke(\n",
        "#     {\n",
        "#         \"style\": \"informative and engaging\",\n",
        "#         \"prompt\": \"How AI is revolutionizing healthcare\",\n",
        "#         \"input\": \"I want a video about AI in healthcare.\",\n",
        "#     }\n",
        "# )\n",
        "\n",
        "# # Print the parsed structured output\n",
        "# print(response)\n"
      ],
      "metadata": {
        "id": "FfkvrQV0RPEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.prompts import ChatPromptTemplate\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain.output_parsers import PydanticOutputParser\n",
        "# from pydantic import BaseModel\n",
        "# from typing import List, Union\n",
        "# import os\n",
        "\n",
        "# # Define the structured output schema\n",
        "# class ScriptPart(BaseModel):\n",
        "#     text: str\n",
        "#     vid: Union[str, None]  # Description of video clip or None\n",
        "#     image: Union[str, None]  # Description of image or None\n",
        "#     overlay_text: Union[str, None]  # Text overlay on screen if necessary\n",
        "\n",
        "# class EducationalContent(BaseModel):\n",
        "#     title: str\n",
        "#     thumbnail: str  # Description for thumbnail generation\n",
        "#     script: List[ScriptPart]  # List of script parts\n",
        "\n",
        "# # Set OpenAI API key\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# # Initialize OpenAI client\n",
        "# llm = ChatOpenAI(\n",
        "#     model=\"gpt-4\",\n",
        "#     temperature=0,\n",
        "#     max_tokens=3000,  # Adjust as needed\n",
        "#     request_timeout=30,  # Optional timeout\n",
        "#     verbose=True,\n",
        "# )\n",
        "\n",
        "# # Define the parser\n",
        "# parser = PydanticOutputParser(pydantic_object=EducationalContent)\n",
        "\n",
        "# # Create the prompt template\n",
        "# prompt_template = ChatPromptTemplate.from_messages(\n",
        "#     [\n",
        "#         (\n",
        "#             \"system\",\n",
        "#             \"You are a YouTube video director, scriptwriter, and producer. Given the user's style {style} and prompt {topic}, write a detailed script for the video. It should include:\"\n",
        "#             \"\\n- A catchy title\"\n",
        "#             \"\\n- Thumbnail description (detailed enough for an image generator)\"\n",
        "#             \"\\n- A script with parts containing:\"\n",
        "#             \"\\n    - Text spoken in the video\"\n",
        "#             \"\\n    - Description of corresponding video clips or images\"\n",
        "#             \"\\n    - Overlay text if necessary\"\n",
        "#             \"\\n{format_instructions}\"\n",
        "#         )\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# # Format the prompt with specific inputs\n",
        "# formatted_prompt = prompt_template.format_prompt(\n",
        "#     style=\"informative and engaging\",\n",
        "#     topic=\"How AI is revolutionizing healthcare\",\n",
        "#     format_instructions=parser.get_format_instructions()\n",
        "# )\n",
        "\n",
        "# # Invoke the LLM with the formatted prompt\n",
        "# response = llm(formatted_prompt.to_messages())\n",
        "\n",
        "# # Parse the output into the structured format\n",
        "# structured_output = parser.parse(response.content)\n",
        "\n",
        "# # Print the structured output\n",
        "# structured_output.dict()"
      ],
      "metadata": {
        "id": "qZJRIIblUVnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from moviepy.editor import *\n",
        "\n",
        "# # Paths to assets\n",
        "# asset_dir  = \"/content/drive/MyDrive/semicolon\"\n",
        "# audio_path = f\"{asset_dir}/audio.mp3\"\n",
        "# video_path = f\"{asset_dir}/muted_vid.mp4\"\n",
        "# image_path = f\"{asset_dir}/image.jpeg\"\n",
        "# text = \"hello brother\"\n",
        "\n",
        "# # Load assets\n",
        "# audio = AudioFileClip(audio_path)\n",
        "# image = ImageClip(image_path, duration=audio.duration/2).set_audio(audio)\n",
        "# video = VideoFileClip(video_path).subclip(0, audio.duration/2).set_audio(audio)\n",
        "\n",
        "# # Add text overlay\n",
        "# def add_text_overlay(clip, text):\n",
        "#     txt_clip = TextClip(text, fontsize=50, color='white', font=\"Arial-Bold\")\n",
        "#     txt_clip = txt_clip.set_position('center').set_duration(clip.duration)\n",
        "#     return CompositeVideoClip([clip, txt_clip])\n",
        "\n",
        "# # Combine clips\n",
        "# image_with_text = add_text_overlay(image, text)\n",
        "# video_with_text = add_text_overlay(video, text)\n",
        "# final_video = concatenate_videoclips([image_with_text, video_with_text])\n",
        "\n",
        "# final_video = final_video.set_audio(audio)\n",
        "\n",
        "# # Write the output video\n",
        "# output_path = f\"{asset_dir}/output_video.mp4\"\n",
        "# final_video.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
        "\n",
        "# print(f\"Video saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "GNLEBgiMzJum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from moviepy.editor import *\n",
        "# from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# # Paths to assets\n",
        "# asset_dir = \"/content/drive/MyDrive/semicolon\"\n",
        "# audio_path = f\"{asset_dir}/audio.mp3\"\n",
        "# video_path = f\"{asset_dir}/muted_vid.mp4\"\n",
        "# image_path = f\"{asset_dir}/image.jpeg\"\n",
        "# text = \"hello\\nbrother\"\n",
        "\n",
        "# # Function to create centered text overlay as an image\n",
        "# def create_text_overlay(text, size, font_path=\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", font_size=50, color=\"white\"):\n",
        "#     img = Image.new(\"RGBA\", size, (0, 0, 0, 0))  # Transparent background\n",
        "#     draw = ImageDraw.Draw(img)\n",
        "#     font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "#     # Draw text centered in the image using the anchor parameter\n",
        "#     draw.multiline_text(\n",
        "#         (size[0] // 2, size[1] // 2),  # Center of the image\n",
        "#         text,\n",
        "#         fill=color,\n",
        "#         font=font,\n",
        "#         anchor=\"mm\",  # Middle alignment for horizontal and vertical\n",
        "#         align=\"center\",  # Center alignment for multiline\n",
        "#     )\n",
        "#     return img\n",
        "\n",
        "# # Load audio and video clips\n",
        "# audio = AudioFileClip(audio_path).subclip(0, 7)  # Trim audio to 7 seconds\n",
        "# video_clip = VideoFileClip(video_path).subclip(0, 5)  # Use the first 5 seconds of the video\n",
        "\n",
        "# # Resize video clip to a standard size\n",
        "# video_clip = video_clip.resize(height=720)  # Adjust height; width is scaled automatically\n",
        "\n",
        "# # Create an image clip with text overlay\n",
        "# image_clip = ImageClip(image_path, duration=2).resize(height=720)  # Match video height\n",
        "# overlay_size = image_clip.size\n",
        "# text_overlay_image = create_text_overlay(text, overlay_size)\n",
        "# text_overlay_path = f\"{asset_dir}/text_overlay.png\"\n",
        "# text_overlay_image.save(text_overlay_path)\n",
        "\n",
        "# # Add text overlay to the image clip\n",
        "# text_overlay_clip = ImageClip(text_overlay_path, duration=2).set_position(\"center\")\n",
        "# image_with_text = CompositeVideoClip([image_clip, text_overlay_clip])\n",
        "\n",
        "# # Combine image and video clips\n",
        "# final_video = concatenate_videoclips([image_with_text, video_clip], method=\"compose\")  # Use 'compose' for better handling\n",
        "# final_video = final_video.set_audio(audio)\n",
        "\n",
        "# # Write the output video\n",
        "# output_path = f\"{asset_dir}/output_video.mp4\"\n",
        "# final_video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\", fps=24)\n",
        "\n",
        "# print(f\"Video saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "as-dbBM4Vkiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from moviepy.editor import *\n",
        "# from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# # Paths to assets\n",
        "# asset_dir = \"/content/drive/MyDrive/semicolon\"\n",
        "# audio_path = f\"{asset_dir}/audio.mp3\"\n",
        "# video_path = f\"{asset_dir}/muted_vid.mp4\"\n",
        "# image_path = f\"{asset_dir}/image.jpeg\"\n",
        "# text = \"hello\\nbrother\"\n",
        "\n",
        "# # Function to create centered text overlay as an image\n",
        "# def create_text_overlay(text, size, font_path=\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", font_size=50, color=\"white\"):\n",
        "#     img = Image.new(\"RGBA\", size, (0, 0, 0, 0))  # Transparent background\n",
        "#     draw = ImageDraw.Draw(img)\n",
        "#     font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "#     # Draw text centered in the image using the anchor parameter\n",
        "#     draw.multiline_text(\n",
        "#         (size[0] // 2, size[1] // 2),  # Center of the image\n",
        "#         text,\n",
        "#         fill=color,\n",
        "#         font=font,\n",
        "#         anchor=\"mm\",  # Middle alignment for horizontal and vertical\n",
        "#         align=\"center\",  # Center alignment for multiline\n",
        "#     )\n",
        "#     return img\n",
        "\n",
        "# # Load assets\n",
        "# audio = AudioFileClip(audio_path).subclip(0, 7)  # Trim audio to 7 seconds\n",
        "# video_clip = VideoFileClip(video_path).subclip(0, 5)  # Use the first 5 seconds of the video\n",
        "\n",
        "# # Resize video clip to a standard size\n",
        "# video_clip = video_clip.resize(height=720)  # Adjust height; width is scaled automatically\n",
        "\n",
        "# # Create an image clip with text overlay\n",
        "# overlay_size = video_clip.size\n",
        "# text_overlay_image = create_text_overlay(text, overlay_size)\n",
        "# text_overlay_path = f\"{asset_dir}/text_overlay.png\"\n",
        "# text_overlay_image.save(text_overlay_path)\n",
        "\n",
        "# # Add text overlay to the video clip\n",
        "# text_overlay_clip = ImageClip(text_overlay_path, duration=5).set_position(\"center\")  # 5 seconds of overlay\n",
        "# video_with_text = CompositeVideoClip([video_clip, text_overlay_clip])\n",
        "\n",
        "# # Combine video with text overlay and audio\n",
        "# final_video = video_with_text.set_audio(audio)\n",
        "\n",
        "# # Write the output video\n",
        "# output_path = f\"{asset_dir}/video_with_text_overlay.mp4\"\n",
        "# final_video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\", fps=24)\n",
        "\n",
        "# print(f\"Video saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "EqDZVIP6XWJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from moviepy.editor import *\n",
        "# from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# # Paths to assets\n",
        "# asset_dir = \"/content/drive/MyDrive/semicolon\"\n",
        "# audio_path = f\"{asset_dir}/audio.mp3\"\n",
        "# video_path = f\"{asset_dir}/muted_vid.mp4\"\n",
        "# image_path = f\"{asset_dir}/image.jpeg\"\n",
        "# text = \"hello\\nbrother\"\n",
        "\n",
        "# # Function to create centered text overlay as an image\n",
        "# def create_text_overlay(text, size, font_path=\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", font_size=50, color=\"white\"):\n",
        "#     img = Image.new(\"RGBA\", size, (0, 0, 0, 0))  # Transparent background\n",
        "#     draw = ImageDraw.Draw(img)\n",
        "#     font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "#     # Draw text centered in the image\n",
        "#     draw.multiline_text(\n",
        "#         (size[0] // 2, size[1] // 2),  # Center of the image\n",
        "#         text,\n",
        "#         fill=color,\n",
        "#         font=font,\n",
        "#         anchor=\"mm\",  # Middle alignment for horizontal and vertical\n",
        "#         align=\"center\",  # Center alignment for multiline\n",
        "#     )\n",
        "#     return img\n",
        "\n",
        "# # Load assets\n",
        "# audio = AudioFileClip(audio_path).subclip(0, 7)  # Trim audio to match video duration\n",
        "# video_clip = VideoFileClip(video_path).subclip(0, 5)  # Use the first 5 seconds of the video\n",
        "\n",
        "# # Create text overlay for the image\n",
        "# image_clip = ImageClip(image_path, duration=2)  # Display image for 2 seconds\n",
        "# overlay_size = image_clip.size\n",
        "# text_overlay_image = create_text_overlay(text, overlay_size)\n",
        "# text_overlay_path = f\"{asset_dir}/text_overlay.png\"\n",
        "# text_overlay_image.save(text_overlay_path)\n",
        "\n",
        "# # Add text overlay to the image\n",
        "# text_overlay_clip = ImageClip(text_overlay_path, duration=2).set_position(\"center\")\n",
        "# image_with_text = CompositeVideoClip([image_clip, text_overlay_clip])\n",
        "# text_overlay_clip = ImageClip(text_overlay_path, duration=5).set_position(\"center\")\n",
        "# vid_with_text = CompositeVideoClip([video_clip, text_overlay_clip])\n",
        "\n",
        "# # Combine image and video\n",
        "# final_video = concatenate_videoclips([image_with_text, vid_with_text], method=\"compose\")  # Use 'compose' for better handling\n",
        "\n",
        "# # Add audio to the final video\n",
        "# final_video = final_video.set_audio(audio)\n",
        "\n",
        "# # Write the output video\n",
        "# output_path = f\"{asset_dir}/final_video.mp4\"\n",
        "# final_video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\", fps=10)\n",
        "\n",
        "# print(f\"Video saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "H_6sQPMwaVlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # download yt vid\n",
        "# # Define paths\n",
        "#     download_dir = Path(\"/content/downloads\")\n",
        "#     download_dir.mkdir(exist_ok=True)\n",
        "\n",
        "#     video_output = download_dir / \"video.mp4.webm\"\n",
        "#     audio_output = download_dir / \"audio.mp3\"\n",
        "#     muted_vid_output = download_dir / \"muted_vid.mp4\"\n",
        "\n",
        "#     # Download video\n",
        "#     ydl_opts = {\n",
        "#         'outtmpl': str(video_output),\n",
        "#         'format': 'bestvideo+bestaudio/best',\n",
        "#     }\n",
        "\n",
        "#     try:\n",
        "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "#             ydl.download([url])\n",
        "#     except Exception as e:\n",
        "#         raise HTTPException(status_code=400, detail=f\"Error downloading video: {e}\")\n",
        "\n",
        "#     # Extract audio using MoviePy"
      ],
      "metadata": {
        "id": "jj5ZVr_fDsrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}